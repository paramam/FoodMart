{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px\">\n",
    "<hr style=\"height:3px\">\n",
    "\n",
    "#   Data Challenge : Analyzing Food-Mart Data\n",
    "\n",
    "\n",
    "<hr style=\"height:1px\">\n",
    "<hr style=\"height:3px\">\n",
    "\n",
    "\n",
    "## Instructions and the Problem Statement : \n",
    "\n",
    "In raw_data folder, you should find 4 inter-related datasets: a dataset of **transactions**, a dataset of **products**, a dataset of **product_classes**, and a dataset with information about **promotions**. The original source is a freely available Foodmart dataset, downloaded from [here](https://sites.google.com/a/dlpage.phi-integration.com/pentaho/mondrian/mysql-foodmart-database/foodmart_mysql.tar.gz). You might need to do some cleaning to the data to get it into a workable state.\n",
    "\n",
    "**Question 1**\n",
    "\n",
    "Management is trying to better understand what is happening at these food marts. To that end, please create some visualizations to help us better understand the following dimensions of the Foodmart data:\n",
    "- Category of products sold\n",
    "- Brand of products sold\n",
    "\n",
    "**Question 2**\n",
    "\n",
    "Foodmart is developing their strategy for the next year. One of their goals is to increase sales and profitability. Please provide the executive team with insights from the data that highlight growth opportunities. Here are some ideas to get you started:\n",
    "\n",
    "- Expand product offerings: which products or categories should we expand and why?\n",
    "- Offer more promotions: how should we target our promotions and why?\n",
    "- Market to a certain customer segment: what segment of customers should we market to and how?\n",
    "\n",
    "Feel free to think of other ideas. Please focus on only 1 to 2 opportunities and provide an executive summary of your recommendations, the potential impact, and what data you found to support your strategy.\n",
    "\n",
    "\n",
    "## Tools used and the Solution Sequence : \n",
    "\n",
    "ALL analysis for the given problem was done using a combination of **Python** and **SQL** (PostGreSQL). The list of all packages installed in the **virtual environment** where the codes were built has been included in the folder as **requirements.txt** and can be extracted if needed. \n",
    "\n",
    "While those SQL queries that produce an output table can be run from within the ipython notebook - some queries that produce new tables or produce row counts etc for verification purposes need to be run outside from the console after logging into the database.\n",
    "\n",
    "The solution has been split into two iPython Notebooks:\n",
    "\n",
    "- [Data_Visualization.ipynb](Data_Visualization.ipynb)  --(Question#1)\n",
    "        \n",
    "- [Sales_Analysis.ipynb](Sales_Analysis.ipynb)      --(Question#2)\n",
    "\n",
    "An **executive summary** for the entire analysis has been included near the end of the Sales_Analysis notebook.\n",
    "\n",
    "In this notebook I have outlined the initial steps taken to :  \n",
    "\n",
    "- Clean the Data\n",
    "- Create a SQL database and \n",
    "- Load the data onto SQL tables \n",
    "\n",
    "\n",
    "<hr style=\"height:1px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy_utils import database_exists, create_database\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('notebook_repr_html',False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 1 : \n",
    "### Cleaning the given data tables : \n",
    "\n",
    "The following steps were taken to clean the data : \n",
    "\n",
    "- File headers had whitespace between column names which had to be removed\n",
    "- Many columns with string data types had quotes('') encasing the variables - these were removed\n",
    "- The promotions file had a column with multiple comma-separated entries which needed special treatment to be read into a pandas data frame\n",
    "- Some numeric columns in transaction table had string data types that needed conversion\n",
    "- Promotion table had one NULL entry which we removed from our analysis \n",
    "- Transaction table had NULL values in the last column which was a variable we did not need for our analysis\n",
    "- Start and End date columns in promotion table were converted from string to datetime datatype\n",
    "\n",
    "The dataframes were then loaded into the Database : \n",
    "\n",
    "$$ CSV -> Data Frame (cleaning) -> SQL-Table $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to remove quotes from variables and convert numbers from strings\n",
    "\n",
    "def cleaner(acolumn):\n",
    "    try:\n",
    "        cleaned = acolumn.str.replace('\\'','')\n",
    "    except:\n",
    "        cleaned = acolumn\n",
    "    return cleaned\n",
    "\n",
    "def data_cleaner(filename):\n",
    "    tname = pd.read_csv(filename)\n",
    "    colname = []\n",
    "    for item in tname.columns:\n",
    "        colname.append(item)\n",
    "    for col in colname:\n",
    "        tname[col] = cleaner(tname[col])\n",
    "    return tname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Making the tables from csv files : \n",
    "\n",
    "product = data_cleaner('product.csv')\n",
    "product_class = data_cleaner('product_class.csv')\n",
    "transactions = data_cleaner('transactions.csv')\n",
    "\n",
    "# Making the promotion table separately : \n",
    "\n",
    "promotion = pd.read_csv('promotion.csv', quotechar=\"'\")\n",
    "for item in promotion.columns:\n",
    "    promotion[item] = cleaner(promotion[item])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Converting string datatype in some columns to numbers\n",
    "transactions[['store_sales','store_cost','unit_sales']] = transactions[['store_sales','store_cost','unit_sales']].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to check for null values in the tables\n",
    "\n",
    "def check_4_null(tablename):\n",
    "    null_position = pd.isnull(tablename).any(1).nonzero()\n",
    "    if tablename.iloc[null_position].size == 0 :\n",
    "        print 'No Nulls'\n",
    "    else:\n",
    "        print 'Need to find nulls'         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Nulls\n",
      "No Nulls\n",
      "Need to find nulls\n",
      "Need to find nulls\n"
     ]
    }
   ],
   "source": [
    "list_of_tables = [product,product_class,transactions,promotion]\n",
    "for tables in list_of_tables:\n",
    "    check_4_null(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "promotion = promotion.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A new variable - Profit\n",
    "\n",
    "I defined a new variable Profit and added it to the transactions table. \n",
    "The following form of profit equation was used for all analysis henceforth :  \n",
    "\n",
    "            $$   Profit =  { (Store     Sales - Store     Cost) } * { Unit Sales } $$\n",
    "          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transactions['profit'] = (transactions.store_sales - transactions.unit_sales)*transactions.store_cost  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For the initial date-analysis the start_date and end_date columns in tables were not in the correct format \n",
    "# The convertion was done in SQL - this was run inside database\n",
    "\n",
    "sql_query = \"\"\"UPDATE promotion SET end_date=to_date(end_date, 'YYYY-MM-DD');\"\"\"  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 2 : \n",
    "### Making SQL Database and loading tables\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a Database for all analysis\n",
    "! createdb etsy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setting up connection using SQL Alchemy : \n",
    "dbname = 'etsy'\n",
    "username = 'parama'\n",
    "engine = create_engine('postgres://%s@localhost/%s'%(username,dbname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setting up connection using Psycopg2 : \n",
    "try:\n",
    "    conn = psycopg2.connect(database = 'etsy', user = 'parama' , password = '###')\n",
    "except:\n",
    "    print 'Unable to connect'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sql_table_maker(tname,name):    \n",
    "    tname.to_sql(name,engine)\n",
    "    print name + ' was created!'    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product was created!\n",
      "product_class was created!\n",
      "transactions was created!\n",
      "promotion was created!\n"
     ]
    }
   ],
   "source": [
    "list_of_tables = [product,product_class,transactions,promotion]\n",
    "list_of_tablenames = ['product','product_class','transactions','promotion']\n",
    "for index in range(4):\n",
    "    sql_table_maker(list_of_tables[index],list_of_tablenames[index])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
